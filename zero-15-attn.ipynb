{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_head = '../input/zero-models-attn/'\n",
    "# os.listdir(model_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = '../input/another-animals-dataset/ex_imgs/'\n",
    "\n",
    "cat_list = list(sorted(os.listdir(head)))\n",
    "cat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_csv = pd.read_csv('../input/another-animals-dataset/labels/classes.txt', sep='\\t', header=None)\n",
    "class_csv.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_label_dict = {}\n",
    "for cls in class_csv.values:\n",
    "    class_to_label_dict[cls[1]] = cls[0] - 1\n",
    "\n",
    "label_to_class_dict = {v: k for k, v in class_to_label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class_dict[0], class_to_label_dict[label_to_class_dict[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_csv = pd.read_csv('../input/another-animals-dataset/labels/predicate-matrix-binary.txt', sep=' ', header=None)\n",
    "attr_csv.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_matrix = attr_csv.values.astype(np.float32)\n",
    "attr_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "label_list = []\n",
    "\n",
    "\n",
    "for cat in cat_list:\n",
    "    c_img_list = [head + cat + '/' + ipl for ipl in os.listdir(head + cat)]\n",
    "    img_list += c_img_list\n",
    "    label_list += [class_to_label_dict[cat]] * len(c_img_list)\n",
    "    \n",
    "len(img_list), img_list[0], len(label_list), label_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_head = '../input/awa-dataset/imgs_e/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_list:\n",
    "    c_img_list = [a_head + cat + '/' + ipl for ipl in os.listdir(a_head + cat)]\n",
    "    img_list += c_img_list\n",
    "    label_list += [class_to_label_dict[cat]] * len(c_img_list)\n",
    "    \n",
    "len(img_list), img_list[-1], len(label_list), label_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open(img_list[0])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_list[-1])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AwaDataSet(Dataset):\n",
    "    #  img_path_list: text. labels: text, need to locate through\n",
    "    def __init__(self, img_path_list, label_list, x_transform):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.x_transform = x_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "#         print(self.img_path_list[idx])\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(self.img_path_list[idx])\n",
    "        except:\n",
    "            img = Image.fromarray(np.random.randint(0, 255, (64, 64, 3), dtype=np.uint8))\n",
    "                \n",
    "        if head in self.img_path_list[idx]:\n",
    "            if np.random.randint(1000) <= 125:\n",
    "                img = ImageOps.mirror(img)\n",
    "\n",
    "            if np.random.randint(1000) <= 50:\n",
    "                img = img.rotate(np.random.randint(-18, 18))\n",
    "\n",
    "        else:\n",
    "            img = img.convert('RGBA')\n",
    "            \n",
    "            blank = img.copy()\n",
    "        \n",
    "            if np.random.randint(1000) <= 125:\n",
    "                img = ImageOps.mirror(img)\n",
    "\n",
    "            if np.random.randint(1000) <= 50:\n",
    "                img = img.rotate(np.random.randint(-18, 18), expand=True)\n",
    "                \n",
    "            width, height = img.size\n",
    "            target_size = max(img.size)\n",
    "\n",
    "            blank = blank.resize((target_size * 3, target_size * 3))\n",
    "            blank = blank.crop((target_size, target_size, 2 * target_size, 2 * target_size))\n",
    "            \n",
    "            blank.paste(img, (int((max(img.size) - width) / np.random.uniform(1.75, 2.25)),\n",
    "                          int((max(img.size) - height) / np.random.uniform(1.75, 2.25))), img)\n",
    "            img = blank\n",
    "            \n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((128, 128))\n",
    "        img = np.array(img, dtype=np.float32) / 255\n",
    "\n",
    "        if np.random.randint(1000) <= 125:\n",
    "            img = np.clip(img * np.random.uniform(0.8, 1.28), 0, 1)\n",
    "        \n",
    "        img = self.x_transform(img)\n",
    "        \n",
    "        label = self.label_list[idx]\n",
    "        \n",
    "        attr = attr_matrix[label]\n",
    "\n",
    "        return img, label, attr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,) * 3, std=(0.5,) * 3),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AwaDataSet(img_list, label_list, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in train_loader:\n",
    "    img, label, attr = db\n",
    "#     print(img.mean())\n",
    "#     print(label)\n",
    "#     print(label)\n",
    "    \n",
    "    print(label_to_class_dict[label[0].item()])\n",
    "    \n",
    "    img = img[0].cpu().data.numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    plt.imshow(img * 0.5 + 0.5)\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight init..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define spectral norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "\n",
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "\n",
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttn(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttn, self).__init__()\n",
    "        self.Q = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.K = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.V = nn.Conv2d(in_dim, in_dim, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            input_size: B * C * W * H\n",
    "            return:\n",
    "                output: self attn value + input\n",
    "                attn: B * N * N (N = W * H)\n",
    "        '''\n",
    "        \n",
    "        b_size, C, W, H = x.size()\n",
    "        \n",
    "        proj_Q = self.Q(x).view(b_size, -1, W * H).permute(0, 2, 1)\n",
    "        proj_K = self.K(x).view(b_size, -1, W * H)\n",
    "        energy = torch.bmm(proj_Q, proj_K)\n",
    "        \n",
    "        attn = self.softmax(energy)\n",
    "        proj_V = self.V(x).view(b_size, -1, W * H)\n",
    "        \n",
    "        output = torch.bmm(proj_V, attn.permute(0, 2, 1))\n",
    "        output = output.view(b_size, C, W, H)\n",
    "        \n",
    "        output = self.gamma * output + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        self.sigma = nn.Parameter(torch.ones(512))\n",
    "        self.myu = nn.Parameter(torch.zeros(512))\n",
    "        \n",
    "        self.sigma_256 = nn.Parameter(torch.ones(256))\n",
    "        self.myu_256 = nn.Parameter(torch.zeros(256))\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(85, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(128, 192, bias=False), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(192, 256, bias=False),\n",
    "        )\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            SpectralNorm(nn.ConvTranspose2d(256 + 256, 1024, 4, 1, 0, bias=False)),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            # size: 4 x 4\n",
    "\n",
    "            SpectralNorm(nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            # size: 8 x 8\n",
    "\n",
    "            SpectralNorm(nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            # size: 16 x 16\n",
    "\n",
    "            SpectralNorm(nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            SelfAttn(128),\n",
    "            # size: 32 x 32\n",
    "            \n",
    "            SpectralNorm(nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            SelfAttn(64),\n",
    "#             nn.Tanh()\n",
    "            # size: 64 x 64     \n",
    "            \n",
    "            # size: 128 x 128 \n",
    "        )\n",
    "        \n",
    "        self.output_awa = nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False)\n",
    "        self.output_rf = nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mode='attr'):  \n",
    "        \n",
    "        if mode == 'attr':\n",
    "            \n",
    "            # y: attr\n",
    "            # x: noise\n",
    "            \n",
    "            y = x[1].view(-1, 85)\n",
    "            y = self.encoder(y).view(-1, 256)\n",
    "            \n",
    "            x = x[0].view(-1, 256)\n",
    "            x = self.sigma_256 * x + self.myu_256\n",
    "            \n",
    "            x = torch.cat((x, y), dim=1).view(-1, 512, 1, 1)\n",
    "            \n",
    "        elif mode == 'rf':\n",
    "            \n",
    "            # x: noise\n",
    "            \n",
    "            x = x.view(-1, 512)\n",
    "            x = self.sigma * x + self.myu\n",
    "            x = x.view(-1, 512, 1, 1)\n",
    "            \n",
    "        elif mode == 'rec':\n",
    "            \n",
    "            # y: attr\n",
    "            # x: enc\n",
    "            \n",
    "            y = x[1].view(-1, 85)\n",
    "            y = self.encoder(y).view(-1, 256)\n",
    "            \n",
    "            x = x[0].view(-1, 256)\n",
    "            \n",
    "            x = torch.cat((x, y), dim=1).view(-1, 512, 1, 1)\n",
    "        \n",
    "        x = self.main(x)\n",
    "        \n",
    "        if mode == 'attr':\n",
    "            x = self.output_awa(x)\n",
    "            x = self.tanh(x)\n",
    "\n",
    "        elif mode == 'rf':\n",
    "            x = self.output_awa(x)\n",
    "            x = self.tanh(x)\n",
    "        \n",
    "        elif mode == 'rec':\n",
    "            x = self.output_awa(x)\n",
    "            x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesy = torch.ones(4, 85, 1, 1).cuda()\n",
    "tesn = torch.ones(4, 256, 1, 1).cuda()\n",
    "tes_output = G((tesn, tesy), mode='attr')\n",
    "tes_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesz = torch.ones(4, 512, 1, 1).cuda()\n",
    "tes_output_ = G(tesz, mode='rf')\n",
    "tes_output_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_output_ = G((tesn, tesy), mode='rec')\n",
    "tes_output_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_head + 'g_model.pth'):\n",
    "    G.load_state_dict(torch.load(model_head + 'g_model.pth'))\n",
    "    print('load...')\n",
    "else:\n",
    "    G.apply(weights_init)\n",
    "    print('init...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            SpectralNorm(nn.Conv2d(3, 32, 4, 2, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # size: 64 x 64\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(32, 64, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # size: 32 x 32\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(64, 128, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(128),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # size: 16 x 16\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(128, 256, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(256),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            # size: 8 x 8\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(256, 512, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(512),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            SelfAttn(512),\n",
    "            # size: 4 x 4\n",
    "            \n",
    "#             nn.Conv2d(512, 1024, 4, 2, 1, bias=False),\n",
    "            SpectralNorm(nn.Conv2d(512, 1024, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(1024),\n",
    "            nn.InstanceNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            SelfAttn(1024),\n",
    "            # size: 2 x 2\n",
    "            \n",
    "#             nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.rf = nn.Conv2d(1024, 1, 4, 2, 1, bias=False)\n",
    "        self.encoder = nn.Conv2d(1024, 256, 4, 2, 1, bias=False)\n",
    "        self.clsfy = nn.Linear(256, 50, bias=False)\n",
    "                \n",
    "    def forward(self, x, mode='rf', clsfy=False):\n",
    "        x = self.main(x)\n",
    "        \n",
    "        if mode == 'rf':\n",
    "            x = self.rf(x).view(-1)\n",
    "        elif mode == 'encode':\n",
    "            x = self.encoder(x).view(-1, 256)\n",
    "            if clsfy:\n",
    "                x = self.clsfy(x)\n",
    "            else:\n",
    "                x = x / (torch.sum(x ** 2, dim=1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesx_ = torch.ones(4, 3, 128, 128).cuda()\n",
    "D(tesx_, mode='rf').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesy_ = torch.ones(4, 3, 128, 128).cuda()\n",
    "D(tesy_, mode='encode', clsfy=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesz_ = torch.ones(4, 3, 128, 128).cuda()\n",
    "D(tesz_, mode='encode', clsfy=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_head + 'd_model.pth'):\n",
    "    D.load_state_dict(torch.load(model_head + 'd_model.pth'))\n",
    "    print('load..')\n",
    "else:\n",
    "    D.apply(weights_init)\n",
    "    print('init...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attr_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(attr_encoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(85, 128, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(128, 192, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(192, 256, bias=False),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x / (torch.sum(x ** 2, dim=1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = attr_encoder().cuda()\n",
    "summary(E, (85,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_head + 'e_model.pth'):\n",
    "    E.load_state_dict(torch.load(model_head + 'e_model.pth'))\n",
    "    print('load...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Encoder (for rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class visual_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(visual_encoder, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            SpectralNorm(nn.Conv2d(3, 16, 4, 2, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # size: 64 x 64\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(16, 32, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # size: 32 x 32\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(32, 64, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(128),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # size: 16 x 16\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(64, 128, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(256),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            # size: 8 x 8\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(128, 256, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(512),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "#             Self_Attn(512),\n",
    "            # size: 4 x 4\n",
    "            \n",
    "            SpectralNorm(nn.Conv2d(256, 512, 4, 2, 1, bias=False)),\n",
    "#             nn.BatchNorm2d(1024),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            # size: 2 x 2\n",
    "            \n",
    "#             nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.encoder_output = nn.Conv2d(512, 1024, 4, 2, 1, bias=False)\n",
    "        \n",
    "        self.mu = nn.Linear(1024, 256)\n",
    "        self.logvar = nn.Linear(1024, 256)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.main(x)\n",
    "        x = self.encoder_output(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        \n",
    "        return self.mu(x), self.logvar(x)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        return mu + eps * std\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        mu, logvar = self.encode(x)\n",
    "        x = self.reparameterize(mu, logvar)\n",
    "\n",
    "        x = (x - x.mean(dim=1, keepdim=True)) / (x.std(dim=1, keepdim=True) + 1e-8)\n",
    "        x = x.view(-1, 256, 1, 1)\n",
    "\n",
    "        return x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE = visual_encoder().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesx = torch.ones(4, 3, 128, 128).cuda()\n",
    "[x.size() for x in VE(tesx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(model_head + 've_model.pth'):\n",
    "    VE.load_state_dict(torch.load(model_head + 've_model.pth'))\n",
    "    print('load...')\n",
    "else:\n",
    "    VE.apply(weights_init)\n",
    "    print('init...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vae loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_vae(rec_imgs, imgs, mu, logvar):\n",
    "    \n",
    "    ### remember: the range of output image is (-1, 1),\n",
    "    ### without making it to range(0, 1), using bce_loss would raise some strange error.\n",
    "    \n",
    "#     print(rec_imgs.max(), rec_imgs.min(), imgs.max(), imgs.min())\n",
    "    bce_loss = F.binary_cross_entropy(rec_imgs.view(-1, 3 * 128 * 128), imgs.view(-1, 3 * 128 * 128), reduction='sum')\n",
    "    \n",
    "    kld_loss = - 0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp())\n",
    "    \n",
    "    return (bce_loss + kld_loss) / rec_imgs.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KanCosineSimilarity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KanCosineSimilarity, self).__init__()\n",
    "\n",
    "    def forward(self, x, y, labels):\n",
    "        return 1/2 * torch.mean((labels - F.cosine_similarity(x, y, eps=1e-6)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.sigma_256.mean(), G.sigma.std(), G.myu_256.mean(), G.myu_256.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bce = nn.BCELoss()\n",
    "criterion_mse = nn.MSELoss()\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_cos = KanCosineSimilarity()\n",
    "\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=5e-5, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "e_optimizer = optim.Adam(E.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "ag_optimizer = optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "ae_optimizer = optim.Adam(VE.parameters(), lr=1e-4, betas=(0.5, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 6.4, 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_epoch = 1\n",
    "d_epoch = 1\n",
    "g_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 2e-1\n",
    "decay = 0.9999\n",
    "\n",
    "for epoch in range(20):\n",
    "    d_running_loss_rf = 0.0\n",
    "    d_running_loss_cos = 0.0\n",
    "    d_running_loss_cls = 0.0\n",
    "    \n",
    "    g_running_loss_rf = 0.0\n",
    "    g_running_loss_cos = 0.0\n",
    "    \n",
    "    ae_running_loss = 0.0\n",
    "    \n",
    "    torch.save(G.state_dict(), 'g_model.pth')\n",
    "    torch.save(D.state_dict(), 'd_model.pth')\n",
    "    torch.save(E.state_dict(), 'e_model.pth')\n",
    "    torch.save(VE.state_dict(), 've_model.pth')\n",
    "    \n",
    "    sys.stdout.write('model saved...')\n",
    "    \n",
    "    for i, data_batch in enumerate(train_loader):\n",
    "        \n",
    "        if i % 50 == 49:\n",
    "            print('nc:', nc)\n",
    "        \n",
    "        real_imgs, labels, attrs = data_batch\n",
    "        real_imgs = real_imgs.cuda()\n",
    "        attrs = attrs.cuda()\n",
    "        attrs_ = (attrs - 0.5) / 0.5\n",
    "\n",
    "        b_size = real_imgs.size()[0]\n",
    "        \n",
    "        if b_size == 1:\n",
    "            break\n",
    "            \n",
    "        label_real = labels.cuda().long()\n",
    "        label_fake = (torch.ones_like(label_real) * 50).cuda().long()\n",
    "        \n",
    "        rf_labels_real = torch.ones(b_size).cuda()\n",
    "        rf_labels_fake = torch.zeros(b_size).cuda()\n",
    "        \n",
    "        rf_labels_real_s = 0.7 * rf_labels_real + 0.55 * torch.rand_like(rf_labels_real).cuda()\n",
    "        rf_labels_fake_s = 0.25 * torch.rand_like(rf_labels_fake).cuda()\n",
    "        \n",
    "        rf_labels_real_ = torch.ones(b_size).cuda()\n",
    "        \n",
    "        cos_labels_real = torch.ones(b_size)\n",
    "        cos_labels_fake = torch.zeros(b_size)\n",
    "        cos_labels_real_ = torch.ones(b_size).cuda()\n",
    "        \n",
    "        cos_labels_real_s = cos_labels_real - 0.2 * torch.rand(b_size)\n",
    "        cos_labels_fake_s = 0.375 * torch.rand(b_size) - 0.25\n",
    "        \n",
    "        cos_labels_real = cos_labels_real.cuda()\n",
    "        cos_labels_fake = cos_labels_fake.cuda()\n",
    "        \n",
    "        cos_labels_real_s = cos_labels_real_s.cuda()\n",
    "        cos_labels_fake_s = cos_labels_fake_s.cuda()\n",
    "        \n",
    "        if np.random.randint(1000) < 25:\n",
    "            rf_labels_real, rf_labels_fake = rf_labels_fake, rf_labels_real\n",
    "            rf_labels_real_s, rf_labels_fake_s = rf_labels_fake_s, rf_labels_real_s\n",
    "            \n",
    "        if np.random.randint(1000) < 50:\n",
    "            cos_labels_real, cos_labels_fake = cos_labels_fake, cos_labels_real\n",
    "            cos_labels_real_s, cos_labels_fake_s = cos_labels_fake_s, cos_labels_real_s\n",
    "        \n",
    "        if b_size == 1:\n",
    "            break\n",
    "            \n",
    "        for _ in range(ae_epoch):\n",
    "            VE.zero_grad()\n",
    "            G.zero_grad()\n",
    "            \n",
    "            ### encoder used the encoded latent vector and attr\n",
    "            \n",
    "            enc_outputs, mu, logvar = VE(real_imgs)\n",
    "            \n",
    "            z = torch.randn(b_size, 256, 1, 1).cuda()\n",
    "            f_attr_matrix = torch.abs(torch.randn_like(attrs_)) * attrs_ * 0.55 + attrs_ * 0.7\n",
    "            \n",
    "            rec_imgs = G((enc_outputs, f_attr_matrix), mode='rec')\n",
    "            \n",
    "            ae_loss = 1e-2 * criterion_vae(rec_imgs, real_imgs * 0.5 + 0.5, mu, logvar)\n",
    "            ae_loss.backward()\n",
    "            \n",
    "            ag_optimizer.step()\n",
    "            ae_optimizer.step()\n",
    "            \n",
    "            ae_running_loss += ae_loss.item()\n",
    "            \n",
    "        for _ in range(d_epoch):\n",
    "            # -------------------\n",
    "            D.zero_grad()\n",
    "\n",
    "            d_real_outputs_rf = D(real_imgs + nc * torch.randn_like(real_imgs), mode='rf').view(-1)\n",
    "            d_real_loss_rf = criterion_mse(d_real_outputs_rf, rf_labels_real_s)\n",
    "            \n",
    "            z = torch.randn(b_size, 512, 1, 1).cuda()\n",
    "            fake_imgs = G(z, mode='rf')\n",
    "            \n",
    "            d_fake_outputs_rf = D(fake_imgs.detach() + nc * torch.randn_like(fake_imgs), mode='rf').view(-1)\n",
    "            d_fake_loss_rf = criterion_mse(d_fake_outputs_rf, rf_labels_fake_s)\n",
    "            \n",
    "            d_loss_rf = d_real_loss_rf + d_fake_loss_rf\n",
    "            d_loss_rf.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            d_running_loss_rf += d_loss_rf.item()\n",
    "            \n",
    "            # -------------------\n",
    "            D.zero_grad()\n",
    "            E.zero_grad()\n",
    "            \n",
    "            d_real_encode_v = D(real_imgs + nc * torch.randn_like(real_imgs), mode='encode', clsfy=False)\n",
    "            d_real_encode_s = E(attrs_)\n",
    "\n",
    "            d_real_loss_cos = criterion_cos(d_real_encode_v, d_real_encode_s, cos_labels_real_s)\n",
    "            \n",
    "            z = torch.randn(b_size, 256, 1, 1).cuda()\n",
    "            f_attr_matrix = torch.abs(torch.randn_like(attrs_)) * attrs_ * 0.55 + attrs_ * 0.7\n",
    "            \n",
    "            fake_imgs = G((z, f_attr_matrix), mode='attr')\n",
    "            \n",
    "            d_fake_encode_v = D(fake_imgs + nc * torch.randn_like(real_imgs), mode='encode', clsfy=False)\n",
    "            \n",
    "            d_fake_loss_cos = criterion_cos(d_fake_encode_v, d_real_encode_s, cos_labels_fake_s)\n",
    "            \n",
    "            d_loss_cos = d_real_loss_cos + d_fake_loss_cos\n",
    "            d_loss_cos.backward()\n",
    "            d_optimizer.step()\n",
    "            e_optimizer.step()\n",
    "            \n",
    "            d_running_loss_cos += d_loss_cos.item()\n",
    "            \n",
    "            # -------------------\n",
    "            d_outputs_cls = D(real_imgs, mode='encode', clsfy=True)\n",
    "            \n",
    "            d_loss_cls = criterion_ce(d_outputs_cls, label_real)\n",
    "            \n",
    "            lim = 1.0\n",
    "            d_loss_cls = lim * d_loss_cls\n",
    "            d_loss_cls.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            d_running_loss_cls += d_loss_cls.item() / lim\n",
    "            \n",
    "            # -------------------\n",
    "            \n",
    "            nc *= decay\n",
    "\n",
    "        for _ in range(g_epoch):\n",
    "            # --------------------\n",
    "            G.zero_grad()\n",
    "\n",
    "            z = torch.randn(b_size, 512, 1, 1).cuda()\n",
    "            fake_imgs = G(z, mode='rf')\n",
    "            \n",
    "            d_outputs_rf = D(fake_imgs, mode='rf').view(-1)\n",
    "            g_loss_rf = criterion_mse(d_outputs_rf, rf_labels_real_)\n",
    "            \n",
    "            g_loss_rf.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            g_running_loss_rf += g_loss_rf.item()\n",
    "            \n",
    "            # --------------------\n",
    "            G.zero_grad()\n",
    "            z = torch.randn(b_size, 256, 1, 1).cuda()\n",
    "            f_attr_matrix = torch.abs(torch.randn_like(attrs_)) * attrs_ * 0.55 + attrs_ * 0.7     \n",
    "            \n",
    "            fake_imgs = G((z, f_attr_matrix), mode='attr')\n",
    "            \n",
    "            d_encode_v = D(fake_imgs, mode='encode', clsfy=False)\n",
    "            d_encode_s = E(attrs_)\n",
    "            \n",
    "            g_loss_cos = criterion_cos(d_encode_v, d_encode_s, cos_labels_real_)\n",
    "            g_loss_cos.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            g_running_loss_cos += g_loss_cos.item()\n",
    "            \n",
    "            # --------------------  \n",
    "\n",
    "        t = 50\n",
    "        if i % t == t-1 or i == 0:\n",
    "\n",
    "            print(epoch+1, (i+1) * 64, 'd_loss_rf:', d_running_loss_rf / (t if i != 0 else 1),\n",
    "                  ', d_loss_cos:', d_running_loss_cos / (t if i != 0 else 1), \n",
    "                  ', d_loss_cls:', d_running_loss_cls / (t if i != 0 else 1))\n",
    "            \n",
    "            print(epoch+1, (i+1) * 64, 'g_loss_rf:', g_running_loss_rf / (t if i != 0 else 1),\n",
    "                  ', g_loss_cos:', g_running_loss_cos / (t if i != 0 else 1))\n",
    "            \n",
    "            print('ae_loss:', ae_running_loss / (t if i != 0 else 1))\n",
    "            \n",
    "            d_running_loss_rf = 0.0\n",
    "            d_running_loss_cos = 0.0\n",
    "            d_running_loss_cls = 0.0\n",
    "            \n",
    "            g_running_loss_rf = 0.0\n",
    "            g_running_loss_cos = 0.0\n",
    "            \n",
    "            ae_running_loss = 0.0\n",
    "            \n",
    "            real_samples = real_imgs[:6]\n",
    "            real_samples_ = real_samples.cpu().data.numpy()\n",
    "            real_samples_ = np.transpose(real_samples_, (0, 2, 3, 1))            \n",
    "            \n",
    "            plt.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "            plt.grid(False)\n",
    "            for k in range(6):\n",
    "                plt.subplot(1, 6, k+1)\n",
    "#                 plt.title(label_to_class_dict[f_labels[k]])\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.imshow(real_samples_[k] * 0.5 + 0.5)\n",
    "            plt.show()\n",
    "            \n",
    "            enc_samples, _, _ = VE(real_samples)\n",
    "            f_attr_matrix = torch.abs(torch.randn_like(attrs_)) * attrs_ * 0.55 + attrs_ * 0.7\n",
    "            \n",
    "#             z = torch.randn(4, 256, 1, 1).cuda()\n",
    "#             enc_samples_ = torch.cat((z, enc_samples), dim=1)\n",
    "            rec_samples = G((enc_samples, f_attr_matrix[:6]), mode='rec')\n",
    "            rec_samples_ = rec_samples.cpu().data.numpy()\n",
    "            rec_samples_ = np.transpose(rec_samples_, (0, 2, 3, 1))\n",
    "            \n",
    "            plt.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "            plt.grid(False)\n",
    "            for k in range(6):\n",
    "                plt.subplot(1, 6, k+1)\n",
    "#                 plt.title(label_to_class_dict[f_labels[k]])\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.imshow(rec_samples_[k])\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "            z = torch.randn(6, 256, 1, 1).cuda()\n",
    "\n",
    "            f_attr_matrix = torch.abs(torch.randn_like(attrs_)) * attrs_ * 0.55 + attrs_ * 0.7\n",
    "            fake_imgs = G((z, f_attr_matrix[:6]), mode='attr').cpu().data.numpy()\n",
    "            fake_imgs = np.transpose(fake_imgs, (0, 2, 3, 1))\n",
    "\n",
    "            plt.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "            plt.grid(False)\n",
    "            for k in range(6):\n",
    "                plt.subplot(1, 6, k+1)\n",
    "                plt.title(label_to_class_dict[labels.cpu().data.numpy()[k]])\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.imshow(fake_imgs[k] * 0.5 + 0.5)\n",
    "            plt.show()\n",
    "\n",
    "            z = torch.randn(6, 512, 1, 1).cuda()\n",
    "\n",
    "            fake_imgs = G(z, mode='rf').cpu().data.numpy()\n",
    "            fake_imgs = np.transpose(fake_imgs, (0, 2, 3, 1))\n",
    "\n",
    "            #             f_labels = f_labels.cpu().data.numpy()\n",
    "\n",
    "            plt.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "            plt.grid(False)\n",
    "            for k in range(6):\n",
    "                plt.subplot(1, 6, k+1)\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.imshow(fake_imgs[k] * 0.5 + 0.5)\n",
    "            plt.show()\n",
    "\n",
    "            #         break\n",
    "            #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
